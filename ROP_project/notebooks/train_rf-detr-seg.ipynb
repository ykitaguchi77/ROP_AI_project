{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Train RF-DETR-N (Nano)**\n",
        "\n",
        "RF-DETRは、Roboflowが開発したリアルタイムの物体検出モデルです。\n",
        "このノートブックでは、RF-DETR-N（Nano）モデルをカスタムデータセットでトレーニングします。\n",
        "\n",
        "参考: https://github.com/roboflow/rf-detr\n",
        "\n",
        "---\n",
        "\n",
        "## ⚠️ 使用前の注意\n",
        "\n",
        "**データの前処理は `train_yolo-seg.ipynb` で行ってください。**\n",
        "\n",
        "このノートブックは、`train_yolo-seg.ipynb` で準備されたYOLO形式のデータ（`data/train/`）を\n",
        "COCO形式に変換してRF-DETRでトレーニングします。\n",
        "\n",
        "### ワークフロー\n",
        "1. **`train_yolo-seg.ipynb`** でデータの前処理・分割を実行\n",
        "2. **このノートブック** でYOLO→COCO変換 & RF-DETR-Nトレーニングを実行\n",
        "\n",
        "※ `data/train/` 内のデータは毎回のトレーニングで更新されます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available! GPU: Quadro RTX 5000\n"
          ]
        }
      ],
      "source": [
        "# CUDAが使えるかどうかを確認\n",
        "import torch\n",
        "\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if cuda_available:\n",
        "    print(f\"CUDA is available! GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]\n",
            "PyTorch version: 2.4.1+cu121\n",
            "CUDA available: True\n",
            "PyTorch CUDA version: 12.1\n"
          ]
        }
      ],
      "source": [
        "# 環境の確認\n",
        "import torch\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RF-DETRのインストール\n",
        "# 初回のみ実行してください\n",
        "# !pip install rfdetr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **RF-DETR データセット構造**\n",
        "\n",
        "RF-DETRはCOCO形式のデータセットを使用します。\n",
        "\n",
        "```\n",
        "dataset/\n",
        "├── train/\n",
        "│   ├── image1.jpg\n",
        "│   ├── image2.jpg\n",
        "│   └── _annotations.coco.json\n",
        "├── valid/\n",
        "│   ├── image1.jpg\n",
        "│   └── _annotations.coco.json\n",
        "```\n",
        "\n",
        "既存のYOLO形式データをCOCO形式に変換する必要があります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 1: データの準備**\n",
        "\n",
        "train_yolo-seg.ipynbと同様のデータ前処理を行います。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO Data Directory: C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train\n",
            "COCO Data Directory: C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train_coco\n",
            "Number of classes: 3\n",
            "Classes: ['Fundus', 'Disc', 'Macula']\n"
          ]
        }
      ],
      "source": [
        "# データディレクトリの設定\n",
        "import os\n",
        "\n",
        "# 既存のYOLO形式データのパス\n",
        "YOLO_DATA_DIR = r'C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train'\n",
        "\n",
        "# RF-DETR用のCOCO形式データの出力パス\n",
        "COCO_DATA_DIR = r'C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train_coco'\n",
        "\n",
        "# クラス定義\n",
        "CLASSES = ['Fundus', 'Disc', 'Macula']\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "print(f\"YOLO Data Directory: {YOLO_DATA_DIR}\")\n",
        "print(f\"COCO Data Directory: {COCO_DATA_DIR}\")\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"Classes: {CLASSES}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOLO形式（セグメンテーション）からCOCO形式への変換\n",
        "#\n",
        "# YOLO Segmentation形式:\n",
        "#   class_id x1 y1 x2 y2 x3 y3 ... (normalized coordinates)\n",
        "#\n",
        "# COCO Detection形式:\n",
        "#   annotations.json with bounding boxes\n",
        "\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "def yolo_seg_to_coco(yolo_images_dir, yolo_labels_dir, output_dir, classes, split_name):\n",
        "    \"\"\"\n",
        "    YOLO Segmentation形式からCOCO Detection形式に変換\n",
        "    \n",
        "    Args:\n",
        "        yolo_images_dir: YOLO形式の画像ディレクトリ\n",
        "        yolo_labels_dir: YOLO形式のラベルディレクトリ\n",
        "        output_dir: 出力ディレクトリ\n",
        "        classes: クラスのリスト\n",
        "        split_name: 'train' or 'valid'\n",
        "    \"\"\"\n",
        "    # 出力ディレクトリの作成\n",
        "    output_images_dir = os.path.join(output_dir, split_name)\n",
        "    os.makedirs(output_images_dir, exist_ok=True)\n",
        "    \n",
        "    # COCO形式のアノテーション構造\n",
        "    coco_annotations = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []\n",
        "    }\n",
        "    \n",
        "    # カテゴリの追加\n",
        "    for idx, class_name in enumerate(classes):\n",
        "        coco_annotations[\"categories\"].append({\n",
        "            \"id\": idx,\n",
        "            \"name\": class_name,\n",
        "            \"supercategory\": \"object\"\n",
        "        })\n",
        "    \n",
        "    annotation_id = 0\n",
        "    image_id = 0\n",
        "    \n",
        "    # 画像ファイルのリストを取得\n",
        "    image_files = [f for f in os.listdir(yolo_images_dir) \n",
        "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    \n",
        "    print(f\"Processing {len(image_files)} images for {split_name}...\")\n",
        "    \n",
        "    for img_file in tqdm(image_files, desc=f\"Converting {split_name}\"):\n",
        "        img_path = os.path.join(yolo_images_dir, img_file)\n",
        "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "        label_path = os.path.join(yolo_labels_dir, label_file)\n",
        "        \n",
        "        # 画像サイズの取得\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {img_path}: {e}\")\n",
        "            continue\n",
        "        \n",
        "        # 画像情報の追加\n",
        "        coco_annotations[\"images\"].append({\n",
        "            \"id\": image_id,\n",
        "            \"file_name\": img_file,\n",
        "            \"width\": width,\n",
        "            \"height\": height\n",
        "        })\n",
        "        \n",
        "        # 画像をコピー\n",
        "        dst_img_path = os.path.join(output_images_dir, img_file)\n",
        "        if not os.path.exists(dst_img_path):\n",
        "            shutil.copy(img_path, dst_img_path)\n",
        "        \n",
        "        # ラベルファイルの処理\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            \n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 5:  # 少なくともclass_id + 2点（4座標）が必要\n",
        "                    continue\n",
        "                \n",
        "                class_id = int(parts[0])\n",
        "                \n",
        "                # セグメンテーション座標を取得\n",
        "                coords = list(map(float, parts[1:]))\n",
        "                \n",
        "                # ペアになっていない場合はスキップ\n",
        "                if len(coords) % 2 != 0:\n",
        "                    continue\n",
        "                \n",
        "                # 正規化された座標をピクセル座標に変換\n",
        "                x_coords = [coords[i] * width for i in range(0, len(coords), 2)]\n",
        "                y_coords = [coords[i] * height for i in range(1, len(coords), 2)]\n",
        "                \n",
        "                # バウンディングボックスを計算\n",
        "                x_min = min(x_coords)\n",
        "                y_min = min(y_coords)\n",
        "                x_max = max(x_coords)\n",
        "                y_max = max(y_coords)\n",
        "                \n",
        "                bbox_width = x_max - x_min\n",
        "                bbox_height = y_max - y_min\n",
        "                \n",
        "                # セグメンテーション（ポリゴン）の作成\n",
        "                segmentation = []\n",
        "                for i in range(0, len(coords), 2):\n",
        "                    segmentation.append(coords[i] * width)\n",
        "                    segmentation.append(coords[i + 1] * height)\n",
        "                \n",
        "                # アノテーションの追加\n",
        "                coco_annotations[\"annotations\"].append({\n",
        "                    \"id\": annotation_id,\n",
        "                    \"image_id\": image_id,\n",
        "                    \"category_id\": class_id,\n",
        "                    \"bbox\": [x_min, y_min, bbox_width, bbox_height],\n",
        "                    \"area\": bbox_width * bbox_height,\n",
        "                    \"segmentation\": [segmentation],\n",
        "                    \"iscrowd\": 0\n",
        "                })\n",
        "                annotation_id += 1\n",
        "        \n",
        "        image_id += 1\n",
        "    \n",
        "    # アノテーションファイルの保存\n",
        "    annotations_path = os.path.join(output_images_dir, '_annotations.coco.json')\n",
        "    with open(annotations_path, 'w') as f:\n",
        "        json.dump(coco_annotations, f, indent=2)\n",
        "    \n",
        "    print(f\"Saved {split_name} annotations to {annotations_path}\")\n",
        "    print(f\"  - Images: {len(coco_annotations['images'])}\")\n",
        "    print(f\"  - Annotations: {len(coco_annotations['annotations'])}\")\n",
        "    \n",
        "    return coco_annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Converting Train Data ===\n",
            "Processing 16479 images for train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting train: 100%|██████████| 16479/16479 [02:22<00:00, 116.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved train annotations to C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train_coco\\train\\_annotations.coco.json\n",
            "  - Images: 16479\n",
            "  - Annotations: 16823\n",
            "\n",
            "=== Converting Valid Data ===\n",
            "Processing 4023 images for valid...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Converting valid: 100%|██████████| 4023/4023 [00:36<00:00, 110.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved valid annotations to C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train_coco\\valid\\_annotations.coco.json\n",
            "  - Images: 4023\n",
            "  - Annotations: 4858\n",
            "\n",
            "=== Conversion Complete ===\n"
          ]
        }
      ],
      "source": [
        "# YOLO形式からCOCO形式に変換を実行\n",
        "\n",
        "# 出力ディレクトリのクリア（必要に応じて）\n",
        "if os.path.exists(COCO_DATA_DIR):\n",
        "    print(f\"Removing existing directory: {COCO_DATA_DIR}\")\n",
        "    shutil.rmtree(COCO_DATA_DIR)\n",
        "os.makedirs(COCO_DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Train データの変換\n",
        "train_yolo_images = os.path.join(YOLO_DATA_DIR, 'images', 'train')\n",
        "train_yolo_labels = os.path.join(YOLO_DATA_DIR, 'labels', 'train')\n",
        "\n",
        "print(\"\\n=== Converting Train Data ===\")\n",
        "train_coco = yolo_seg_to_coco(\n",
        "    yolo_images_dir=train_yolo_images,\n",
        "    yolo_labels_dir=train_yolo_labels,\n",
        "    output_dir=COCO_DATA_DIR,\n",
        "    classes=CLASSES,\n",
        "    split_name='train'\n",
        ")\n",
        "\n",
        "# Valid データの変換\n",
        "valid_yolo_images = os.path.join(YOLO_DATA_DIR, 'images', 'valid')\n",
        "valid_yolo_labels = os.path.join(YOLO_DATA_DIR, 'labels', 'valid')\n",
        "\n",
        "print(\"\\n=== Converting Valid Data ===\")\n",
        "valid_coco = yolo_seg_to_coco(\n",
        "    yolo_images_dir=valid_yolo_images,\n",
        "    yolo_labels_dir=valid_yolo_labels,\n",
        "    output_dir=COCO_DATA_DIR,\n",
        "    classes=CLASSES,\n",
        "    split_name='valid'\n",
        ")\n",
        "\n",
        "print(\"\\n=== Conversion Complete ===\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== COCO Format Data Summary ===\n",
            "Train directory: C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train_coco\\train\n",
            "  Files: 16480\n",
            "Valid directory: C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\train_coco\\valid\n",
            "  Files: 4024\n"
          ]
        }
      ],
      "source": [
        "# 変換結果の確認\n",
        "\n",
        "import os\n",
        "\n",
        "def count_files_in_directory(directory):\n",
        "    \"\"\"指定されたディレクトリ内のファイル数をカウントする\"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    return len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
        "\n",
        "train_dir = os.path.join(COCO_DATA_DIR, 'train')\n",
        "valid_dir = os.path.join(COCO_DATA_DIR, 'valid')\n",
        "\n",
        "print(\"=== COCO Format Data Summary ===\")\n",
        "print(f\"Train directory: {train_dir}\")\n",
        "print(f\"  Files: {count_files_in_directory(train_dir)}\")\n",
        "print(f\"Valid directory: {valid_dir}\")\n",
        "print(f\"  Files: {count_files_in_directory(valid_dir)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 2: RF-DETR-N トレーニング**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'RFDETRNano' from 'rfdetr' (c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\rfdetr\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# RF-DETRのインポートとモデルの初期化\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrfdetr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RFDETRNano\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# RF-DETR-Nano モデルの作成\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m RFDETRNano()\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'RFDETRNano' from 'rfdetr' (c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\rfdetr\\__init__.py)"
          ]
        }
      ],
      "source": [
        "# RF-DETRのインポートとモデルの初期化\n",
        "from rfdetr import RFDETRNano\n",
        "\n",
        "# RF-DETR-Nano モデルの作成\n",
        "model = RFDETRNano()\n",
        "\n",
        "print(\"RF-DETR-Nano model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# トレーニングパラメータの設定\n",
        "\n",
        "# トレーニング設定\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "LEARNING_RATE_ENCODER = 1.5e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "RESOLUTION = 560  # RF-DETRは56の倍数が推奨\n",
        "\n",
        "# Early Stopping設定\n",
        "EARLY_STOPPING = True\n",
        "EARLY_STOPPING_PATIENCE = 20\n",
        "\n",
        "# 出力ディレクトリ\n",
        "OUTPUT_DIR = r'C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\runs\\rfdetr'\n",
        "\n",
        "print(\"=== Training Configuration ===\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Resolution: {RESOLUTION}\")\n",
        "print(f\"Output Directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RF-DETR-N トレーニングの実行\n",
        "\n",
        "model.train(\n",
        "    dataset_dir=COCO_DATA_DIR,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    grad_accum_steps=4,\n",
        "    lr=LEARNING_RATE,\n",
        "    lr_encoder=LEARNING_RATE_ENCODER,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    resolution=RESOLUTION,\n",
        "    use_ema=True,\n",
        "    checkpoint_interval=10,\n",
        "    tensorboard=True,\n",
        "    early_stopping=EARLY_STOPPING,\n",
        "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
        "    early_stopping_min_delta=0.001,\n",
        "    early_stopping_use_ema=True,\n",
        "    device=\"cuda\",\n",
        "    output_dir=OUTPUT_DIR\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 3: 推論テスト**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学習済みモデルのロード\n",
        "from rfdetr import RFDETRNano\n",
        "\n",
        "# 学習済みモデルのパス（トレーニング後に生成される）\n",
        "model_path = os.path.join(OUTPUT_DIR, 'best_model.pt')  # パスは実際の出力に合わせて調整\n",
        "\n",
        "# モデルのロード\n",
        "# model = RFDETRNano(pretrain_weights=model_path)\n",
        "model = RFDETRNano()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# テスト画像での推論\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# テスト画像のパス\n",
        "test_image_path = r'C:\\Users\\ykita\\ROP_AI_project\\ROP_project\\data\\ROP_image\\IMG_2025\\IMG_2025_0016.jpg'\n",
        "\n",
        "# 推論実行\n",
        "detections = model.predict(test_image_path, threshold=0.5)\n",
        "\n",
        "# 結果の表示\n",
        "print(f\"Detections: {len(detections)}\")\n",
        "for det in detections:\n",
        "    print(f\"  Class: {det['class']}, Confidence: {det['confidence']:.4f}, BBox: {det['bbox']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 検出結果の可視化\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_detections(image_path, detections, classes, threshold=0.5):\n",
        "    \"\"\"\n",
        "    検出結果を画像に描画して表示\n",
        "    \"\"\"\n",
        "    # 画像の読み込み\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # カラーマップ\n",
        "    colors = [\n",
        "        (255, 0, 0),    # Red\n",
        "        (0, 255, 0),    # Green\n",
        "        (0, 0, 255),    # Blue\n",
        "        (255, 255, 0),  # Yellow\n",
        "        (255, 0, 255),  # Magenta\n",
        "    ]\n",
        "    \n",
        "    # 検出結果の描画\n",
        "    for det in detections:\n",
        "        if det['confidence'] >= threshold:\n",
        "            class_id = det['class_id'] if 'class_id' in det else 0\n",
        "            bbox = det['bbox']\n",
        "            color = colors[class_id % len(colors)]\n",
        "            \n",
        "            # バウンディングボックスの描画\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "            \n",
        "            # ラベルの描画\n",
        "            label = f\"{classes[class_id]}: {det['confidence']:.2f}\"\n",
        "            cv2.putText(img, label, (x1, y1 - 10), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    \n",
        "    # 画像の表示\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'RF-DETR-N Detection Results ({len(detections)} objects)')\n",
        "    plt.show()\n",
        "    \n",
        "    return img\n",
        "\n",
        "# 可視化\n",
        "# result_img = visualize_detections(test_image_path, detections, CLASSES, threshold=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Step 4: トレーニング済みモデルの保存と再開**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# トレーニングの再開（必要に応じて）\n",
        "# \n",
        "# checkpoint_path = os.path.join(OUTPUT_DIR, 'checkpoint_epoch_50.pt')  # 例\n",
        "# \n",
        "# model = RFDETRNano()\n",
        "# model.train(\n",
        "#     dataset_dir=COCO_DATA_DIR,\n",
        "#     epochs=EPOCHS,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     resume=checkpoint_path,\n",
        "#     device=\"cuda\"\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **補足: RF-DETR モデルバリアント**\n",
        "\n",
        "RF-DETRには以下のモデルバリアントがあります：\n",
        "\n",
        "| Model | Parameters | COCO mAP | Speed |\n",
        "|-------|------------|----------|-------|\n",
        "| RF-DETR-N (Nano) | ~5M | ~40 | Fastest |\n",
        "| RF-DETR-B (Base) | ~29M | ~53 | Fast |\n",
        "| RF-DETR-L (Large) | ~128M | ~56 | Moderate |\n",
        "\n",
        "他のバリアントを使用する場合：\n",
        "\n",
        "```python\n",
        "from rfdetr import RFDETRBase, RFDETRLarge\n",
        "\n",
        "model = RFDETRBase()  # Base model\n",
        "model = RFDETRLarge()  # Large model\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# モデルのエクスポート（ONNX形式）\n",
        "# \n",
        "# export_path = os.path.join(OUTPUT_DIR, 'rf_detr_nano.onnx')\n",
        "# model.export(export_path, format='onnx')\n",
        "# print(f\"Model exported to {export_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ropenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
