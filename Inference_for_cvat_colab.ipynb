{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/ROP_AI_project/blob/master/Inference_for_cvat_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QnIT5zsvnSx",
        "outputId": "dad961c8-5828-48cd-841c-3a2b3893b0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# CUDAが使えるかどうかを確認\n",
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "if cuda_available:\n",
        "    print(f\"CUDA is available! GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Video2Img**"
      ],
      "metadata": {
        "id": "--ZQj8HA7tAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_frames(video_path, output_dir):\n",
        "    # 出力ディレクトリの作成\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # 動画の読み込み\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # 総フレーム数の取得\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # tqdmで進捗バーを表示\n",
        "    with tqdm(total=total_frames, desc='フレーム抽出中') as pbar:\n",
        "        frame_count = 0\n",
        "\n",
        "        while True:\n",
        "            # フレームの読み込み\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # 読み込みが終了したらループを抜ける\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # フレームを保存\n",
        "            output_path = os.path.join(output_dir, f'{os.path.basename(output_dir)}_{frame_count:04d}.jpg')\n",
        "            cv2.imwrite(output_path, frame)\n",
        "\n",
        "            frame_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "    # キャプチャの解放\n",
        "    cap.release()\n",
        "\n",
        "    print(f'\\n合計 {frame_count} フレームを抽出しました')\n",
        "\n",
        "def main():\n",
        "    # 入力動画のパス\n",
        "    video_path = r'/content/drive/MyDrive/Deep_learning/ROP_AI_project/ROP_movie/IMG_1703.mp4'\n",
        "\n",
        "    # 出力ディレクトリ\n",
        "    output_dir = r'/content/drive/MyDrive/Deep_learning/ROP_AI_project/ROP_images/IMG_1703'\n",
        "\n",
        "    # フレーム抽出の実行\n",
        "    extract_frames(video_path, output_dir)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "CxyB7m9G7wOP",
        "outputId": "6a2da445-ce92-4301-d70f-090474f02076",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "フレーム抽出中: 100%|██████████| 888/888 [00:45<00:00, 19.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "合計 888 フレームを抽出しました\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RgQuhFnvnSy"
      },
      "source": [
        "# **1枚画像**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: gdrive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "O3_wvfc96gpZ",
        "outputId": "ac6cf84a-1066-4565-9fc5-90ee61867340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install wget"
      ],
      "metadata": {
        "id": "g75rjJxsE7OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZoQm8a4vnSz"
      },
      "outputs": [],
      "source": [
        "\n",
        "from ultralytics import RTDETR\n",
        "import wget\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# モデルが未定義ならロードする\n",
        "try:\n",
        "    model  # 変数modelが定義されているか確認\n",
        "except NameError:\n",
        "    print(\"modelが未定義のため、ロードを実行します。\")\n",
        "    model = RTDETR(r\"/content/drive/MyDrive/Deep_learning/ROP_AI_project/models/rtdetr-l-1700_1703.pt\")\n",
        "\n",
        "# 推論を実行: YOLOの推論\n",
        "image_path = r'/content/drive/MyDrive/Deep_learning/ROP_AI_project/ROP_images/IMG_1703/IMG_1703_0024.jpg'\n",
        "results = model(image_path, save=False)\n",
        "\n",
        "for r in results:\n",
        "    boxes = r.boxes  # YOLOv8の場合\n",
        "\n",
        "    # YOLO形式出力\n",
        "    for box in boxes:\n",
        "        cls_id = int(box.cls[0])  # クラスID\n",
        "        x_center, y_center, width, height = box.xywhn[0]\n",
        "\n",
        "        # YOLO形式: class x_center y_center width height\n",
        "        # 小数点以下6桁で出力したい場合\n",
        "        print(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "    #検出結果を画像に描画して表示\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(r.plot(), cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 結果の保存\n",
        "    #cv2.imwrite('result.jpg', r.plot())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6rFSUzLuvnSz"
      },
      "outputs": [],
      "source": [
        "from ultralytics import RTDETR\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# 出力ディレクトリの作成\n",
        "output_dir = '/content/video/output'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# モデルは既にロード済みと仮定\n",
        "try:\n",
        "    model\n",
        "except NameError:\n",
        "    model = RTDETR(r\"/content/drive/MyDrive/Deep_learning/ROP_AI_project/models/rtdetr-l-1700_1703.pt\")\n",
        "\n",
        "# 入力動画のパス\n",
        "video_path = r'/content/drive/MyDrive/Deep_learning/ROP_AI_project/ROP_movie/IMG_1623_16cm(福嶋）.mp4'\n",
        "output_path = os.path.join(output_dir, 'result.mp4')\n",
        "\n",
        "# 入力動画を開く\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: 動画ファイル '{video_path}' を開けませんでした\")\n",
        "    exit()\n",
        "\n",
        "# 動画の基本情報を取得\n",
        "target_width = 224\n",
        "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# アスペクト比を保持してリサイズ\n",
        "aspect_ratio = original_width / original_height\n",
        "target_height = int(target_width / aspect_ratio)\n",
        "\n",
        "# 出力用のビデオライター設定\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (target_width, target_height))\n",
        "\n",
        "try:\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # フレーム処理の進捗を表示\n",
        "        frame_count += 1\n",
        "        if frame_count % 10 == 0:  # 10フレームごとに進捗を表示\n",
        "            print(f\"Processing: {frame_count}/{total_frames} frames ({(frame_count/total_frames*100):.1f}%)\")\n",
        "\n",
        "        # リサイズ\n",
        "        frame = cv2.resize(frame, (target_width, target_height))\n",
        "\n",
        "        # 推論実行\n",
        "        results = model(frame)\n",
        "\n",
        "        # 結果を描画\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # フレームを書き出し\n",
        "        out.write(annotated_frame)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n処理が中断されました\")\n",
        "finally:\n",
        "    # リソースの解放\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "print(f\"\\n処理が完了しました。\\n保存先: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2bpKciovnSz"
      },
      "source": [
        "# **複数画像**\n",
        "\n",
        "階層構造\n",
        "```\n",
        "archive.zip/\n",
        "   ├── data.yaml  # configuration file\n",
        "   ├── train.txt  # list of train subset image paths\n",
        "   │\n",
        "   ├── images/\n",
        "   │   ├── train/  # directory with images for train subset\n",
        "   │   │    ├── image1.jpg\n",
        "   │   │    ├── image2.jpg\n",
        "   │   │    ├── image3.jpg\n",
        "   │   │    └── ...\n",
        "   ├── labels/\n",
        "   │   ├── train/  # directory with annotations for train subset\n",
        "   │   │    ├── image1.txt\n",
        "   │   │    ├── image2.txt\n",
        "   │   │    ├── image3.txt\n",
        "   │   │    └── ...\n",
        "\n",
        "```\n",
        "\n",
        "***.txt (ラベル)\n",
        "```\n",
        "0 0.260745 0.535950 0.218015 0.030600\n",
        "1 0.760795 0.533850 0.213035 0.043800\n",
        "```\n",
        "\n",
        "daya.yaml\n",
        "```\n",
        "names:\n",
        "  0: Right_eye\n",
        "  1: Left_eye\n",
        "path: .\n",
        "train: train.txt\n",
        "```\n",
        "\n",
        "train.txt\n",
        "```\n",
        "data/images/train/***.jpg\n",
        "data/images/train/***.jpg\n",
        "...(pathの羅列。拡張子を合わせる)\n",
        "```\n",
        "※ラベルや画像と対応を合わせること\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Lcaa5OvnS0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from ultralytics import RTDETR\n",
        "\n",
        "def create_yolo_dataset(orig_image_dir, output_dir, model_path):\n",
        "    \"\"\"\n",
        "    YOLOデータセットの構造を作成する\n",
        "\n",
        "    Args:\n",
        "        orig_image_dir: 元の画像が存在するディレクトリ\n",
        "        output_dir: 出力先のディレクトリ\n",
        "        model_path: RTDETRモデルのパス\n",
        "    \"\"\"\n",
        "    # 進捗バーの設定\n",
        "    progress = tqdm(\n",
        "        total=4,\n",
        "        desc=\"データセット作成\",\n",
        "        bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
        "    )\n",
        "\n",
        "    # 必要なディレクトリを作成\n",
        "    os.makedirs(os.path.join(output_dir, \"labels\", \"train\"), exist_ok=True)\n",
        "    progress.update(1)\n",
        "\n",
        "    # data.yamlの作成\n",
        "    yaml_content = \"\"\"names:\n",
        "  0: Right_eye\n",
        "  1: Left_eye\n",
        "path: .\n",
        "train: train.txt\"\"\"\n",
        "\n",
        "    with open(os.path.join(output_dir, \"data.yaml\"), 'w', encoding='utf-8') as f:\n",
        "        f.write(yaml_content)\n",
        "    progress.update(1)\n",
        "\n",
        "    # モデルのロード\n",
        "    try:\n",
        "        model = RTDETR(model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"モデルのロードに失敗: {e}\")\n",
        "        return\n",
        "\n",
        "    # 画像ファイルのリストを取得\n",
        "    image_files = []\n",
        "    extensions = ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG', '*.tif', '*.TIF', '*.tiff', '*.TIFF']\n",
        "\n",
        "    for ext in extensions:\n",
        "        image_files.extend(glob.glob(os.path.join(orig_image_dir, ext)))\n",
        "\n",
        "    total_files = len(image_files)\n",
        "    print(f\"\\n合計 {total_files} 個のファイルが見つかりました\")\n",
        "\n",
        "    # 推論とラベル生成の進捗バー\n",
        "    inference_progress = tqdm(\n",
        "        total=total_files,\n",
        "        desc=\"推論とラベル生成\",\n",
        "        bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
        "    )\n",
        "\n",
        "    # train.txtの作成とラベルファイルの生成\n",
        "    with open(os.path.join(output_dir, \"train.txt\"), 'w', encoding='utf-8') as f:\n",
        "        for image_path in image_files:\n",
        "            # 元の拡張子を保持\n",
        "            basename = os.path.basename(image_path)\n",
        "            name_without_ext = os.path.splitext(basename)[0]\n",
        "\n",
        "            # 推論を実行\n",
        "            results = model(image_path, save=False)\n",
        "\n",
        "            # ラベルファイルのパス（train/配下に.txt）\n",
        "            label_path = os.path.join(output_dir, \"labels\", \"train\", f\"{name_without_ext}.txt\")\n",
        "\n",
        "            # YOLO形式の推論結果をテキストファイルに書き込み\n",
        "            with open(label_path, 'w', encoding='utf-8') as lf:\n",
        "                for r in results:\n",
        "                    boxes = r.boxes\n",
        "                    for box in boxes:\n",
        "                        cls_id = int(box.cls[0])\n",
        "                        x_center, y_center, width, height = box.xywhn[0]\n",
        "                        line = f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n",
        "                        lf.write(line)\n",
        "\n",
        "            # train.txtにYOLOフォーマットのパスを書き込み\n",
        "            yolo_path = f\"data/images/train/{basename}\"\n",
        "            f.write(f\"{yolo_path}\\n\")\n",
        "            inference_progress.update(1)\n",
        "\n",
        "    inference_progress.close()\n",
        "    progress.update(1)\n",
        "\n",
        "    # ZIP圧縮\n",
        "    print(\"\\nZIP圧縮を開始します...\")\n",
        "    zip_path = output_dir + \".zip\"\n",
        "    total = sum(len(files) for _, _, files in os.walk(output_dir))\n",
        "\n",
        "    with tqdm(total=total, desc=\"ZIP圧縮\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]') as pbar:\n",
        "        for root, _, files in os.walk(output_dir):\n",
        "            for file in files:\n",
        "                pbar.update(1)\n",
        "        shutil.make_archive(os.path.splitext(zip_path)[0], 'zip', output_dir)\n",
        "\n",
        "    progress.update(1)\n",
        "    progress.close()\n",
        "    print(f\"\\nフォルダを {zip_path} に圧縮しました。\")\n",
        "\n",
        "# 使用例\n",
        "if __name__ == \"__main__\":\n",
        "    orig_image_dir = r\"C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\image\"\n",
        "    output_dir = r\"C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\archive\"\n",
        "    model_path = r\"C:\\Users\\ykita\\FacePhoto_instance\\models\\135best_rtdetr.pt\"\n",
        "\n",
        "    create_yolo_dataset(orig_image_dir, output_dir, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5RNc0zwvnS0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8whmGmKvnS0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXCSl61kvnS0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from ultralytics import RTDETR\n",
        "from tqdm import tqdm  # tqdmライブラリをインポート\n",
        "\n",
        "# 1) 画像のフォルダを指定する\n",
        "orig_image_dir = r\"C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\image\"\n",
        "# 2) 出力先のフォルダを指定する。フォルダがなければ作成する\n",
        "dst_parent_dir= r\"C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\archive\" #####\n",
        "dst_label_dir = os.path.join(dst_parent_dir, \"labels\", \"train\")\n",
        "os.makedirs(dst_label_dir, exist_ok=True)\n",
        "\n",
        "# モデルが未定義ならロードする\n",
        "try:\n",
        "    model  # 変数modelが定義されているか確認\n",
        "except NameError:\n",
        "    print(\"modelが未定義のため、ロードを実行します。\")\n",
        "    model_path = r\"C:\\Users\\ykita\\FacePhoto_instance\\models\\135best_rtdetr.pt\"\n",
        "    model = RTDETR(model_path)\n",
        "\n",
        "# 処理対象とする画像の拡張子\n",
        "image_extensions = [\n",
        "    '.jpg', '.jpeg', '.JPG', '.JPEG',\n",
        "    '.png', '.PNG',\n",
        "    '.tif', '.tiff', '.TIF', '.TIFF'\n",
        "]\n",
        "\n",
        "# 指定フォルダ配下の該当画像ファイルをすべて取得\n",
        "image_files = []\n",
        "for ext in image_extensions:\n",
        "    image_files.extend(glob.glob(os.path.join(orig_image_dir, f'*{ext}')))\n",
        "\n",
        "# tqdmで進捗状況を表示しながらループ\n",
        "for image_path in tqdm(image_files, desc='推論中', unit='枚'):\n",
        "    # 推論を実行\n",
        "    results = model(image_path, save=False)\n",
        "\n",
        "    # 画像と同じファイル名（拡張子を除く）でテキストファイル出力\n",
        "    basename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    save_txt_path = os.path.join(dst_label_dir, f\"{basename}.txt\")\n",
        "\n",
        "    # YOLO形式の推論結果をテキストファイルに書き込み\n",
        "    with open(save_txt_path, 'w', encoding='utf-8') as f:\n",
        "        for r in results:\n",
        "            boxes = r.boxes  # YOLOv8系の出力\n",
        "            for box in boxes:\n",
        "                cls_id = int(box.cls[0])\n",
        "                x_center, y_center, width, height = box.xywhn[0]\n",
        "                # YOLO形式: class x_center y_center width height（小数点以下6桁）\n",
        "                line = f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\"\n",
        "                f.write(line)\n",
        "\n",
        "print(\"すべての画像に対する推論が完了し、YOLO形式でラベルを出力しました。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ktyPMXyvnS1"
      },
      "source": [
        "## **CVAT仕様のフォルダ構成に**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to-F2yyIvnS1",
        "outputId": "1f27bc9b-75a1-4ea9-9e2b-11282868fa84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yaml と img_list.txt が、labelsフォルダと同じ階層に作成されました。\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# 現在のlabelsフォルダのパス\n",
        "orig_image_dir = r\"C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\image\"\n",
        "dst_parent_dir = r\"C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\archive\"\n",
        "\n",
        "\n",
        "# yamlとimg_listのパスを定義\n",
        "data_yaml_path = os.path.join(dst_parent_dir, \"data.yaml\")\n",
        "img_list_path = os.path.join(dst_parent_dir, \"train.txt\")\n",
        "\n",
        "# data.yaml を書き込み\n",
        "with open(data_yaml_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"names:\\n\")\n",
        "    f.write(\"  0: Right_eye\\n\")\n",
        "    f.write(\"  1: Left_eye\\n\")\n",
        "    f.write(\"path: .\\n\")\n",
        "    f.write(\"train: train.txt\\n\")\n",
        "\n",
        "# labels_dir配下の .txt ファイルから、img_list.txt を作成\n",
        "txt_files = glob.glob(os.path.join(dst_label_dir, \"*.txt\"))\n",
        "\n",
        "with open(img_list_path, 'w', encoding='utf-8') as f:\n",
        "    for txt_file in txt_files:\n",
        "        basename = os.path.splitext(os.path.basename(txt_file))[0]\n",
        "        f.write(f\"data/images/train/{basename}.jpg\\n\")\n",
        "\n",
        "print(\"data.yaml と img_list.txt が、labelsフォルダと同じ階層に作成されました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAFbZSLgvnS1",
        "outputId": "88c9c811-774c-47f5-c79a-7626e4ee56d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "フォルダを C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\archive.zip に圧縮しました。\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "#dst_parent_dir = r\"C:\\Users\\ykita\\FacePhoto_instance\\inference\\201-295\\archive\"\n",
        "# dst_parent_dirをzip圧縮\n",
        "zip_path = dst_parent_dir + \".zip\"\n",
        "shutil.make_archive(dst_parent_dir, 'zip', dst_parent_dir)\n",
        "\n",
        "print(f\"フォルダを {zip_path} に圧縮しました。\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}