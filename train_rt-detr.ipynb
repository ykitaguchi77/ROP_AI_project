{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inference RT-DETR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! GPU: Quadro RTX 5000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDAが使えるかどうかを確認\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"CUDA is available! GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]\n",
      "PyTorch version: 2.4.1+cu121\n",
      "CUDA available: True\n",
      "PyTorch CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "#環境の確認\n",
    "import torch\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"PyTorch CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 13 00:36:54 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 538.78                 Driver Version: 538.78       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 5000              WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   39C    P8              12W /  80W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/rtdetr-l.pt to 'models\\rtdetr-l.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63.4M/63.4M [00:01<00:00, 35.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\ykita\\ROP_AI_project\\london-buses.jpg: 640x640 16 persons, 2 cars, 1 bus, 993.1ms\n",
      "Speed: 10.2ms preprocess, 993.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import RTDETR\n",
    "import wget\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# RTDETRモデルのダウンロードと初期化\n",
    "model_path = r'models\\rtdetr-l.pt'\n",
    "\n",
    "try:\n",
    "    model = RTDETR(model_path)\n",
    "except:\n",
    "    # モデルディレクトリが存在しない場合は作成\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    \n",
    "    # モデルをダウンロードして指定したパスに保存\n",
    "    wget.download('https://github.com/ultralytics/assets/releases/download/v0.0.0/rtdetr-l.pt', model_path)\n",
    "    model = RTDETR(model_path)\n",
    "\n",
    "# 推論実行\n",
    "image_path = 'london-buses.jpg'\n",
    "results = model(image_path)\n",
    "\n",
    "# 結果の表示と保存\n",
    "for r in results:\n",
    "    # 画像をプロットして表示\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    # plt.imshow(cv2.cvtColor(r.plot(), cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis('off')\n",
    "    # #plt.show()\n",
    "    \n",
    "    # 結果の保存\n",
    "    cv2.imwrite('result.jpg', r.plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test new model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RTDETR(r\"C:\\Users\\ykita\\FacePhoto_instance\\models\\135best_rtdetr.pt\")\n",
    "\n",
    "# 推論実行\n",
    "image_path = r'C:\\Users\\ykita\\FacePhoto_instance\\136-200\\143-20050913-3-123028_47e95b8254c47db2ccab05c9a0234c52f5e985b982c8d624f676dd96820d4020.JPG'\n",
    "results = model(image_path)\n",
    "\n",
    "# 結果の表示と保存\n",
    "for r in results:\n",
    "    # 画像をプロットして表示\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(r.plot(), cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # 結果の保存\n",
    "    cv2.imwrite('result.jpg', r.plot())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\ykita\\FacePhoto_instance\\201-295\\Image\\293-20200311-6-095803_287b73c1d0b04ca725de2651547efd9a530231320625fb361bef3708dc3df9ee.jpg: 640x640 1 Right_eye, 1 Left_eye, 771.9ms\n",
      "Speed: 6.0ms preprocess, 771.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0 0.268958 0.487141 0.170173 0.112953\n",
      "1 0.687053 0.477957 0.160687 0.102739\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import RTDETR\n",
    "import wget\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# モデルが未定義ならロードする\n",
    "try:\n",
    "    model  # 変数modelが定義されているか確認\n",
    "except NameError:\n",
    "    print(\"modelが未定義のため、ロードを実行します。\")\n",
    "    model = RTDETR(r\"C:\\Users\\ykita\\FacePhoto_instance\\models\\135best_rtdetr.pt\")\n",
    "\n",
    "# 推論を実行: YOLOの推論\n",
    "image_path = r'C:\\Users\\ykita\\FacePhoto_instance\\201-295\\Image\\293-20200311-6-095803_287b73c1d0b04ca725de2651547efd9a530231320625fb361bef3708dc3df9ee.jpg'\n",
    "results = model(image_path, save=False)\n",
    "\n",
    "for r in results:\n",
    "    boxes = r.boxes  # YOLOv8の場合\n",
    "\n",
    "    # YOLO形式出力\n",
    "    for box in boxes:\n",
    "        cls_id = int(box.cls[0])  # クラスID\n",
    "        x_center, y_center, width, height = box.xywhn[0]\n",
    "\n",
    "        # YOLO形式: class x_center y_center width height\n",
    "        # 小数点以下6桁で出力したい場合\n",
    "        print(f\"{cls_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    # 検出結果を画像に描画して表示\n",
    "    # plt.figure(figsize=(12, 8))\n",
    "    # plt.imshow(cv2.cvtColor(r.plot(), cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # 結果の保存\n",
    "    #cv2.imwrite('result.jpg', r.plot())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web画像の場合\n",
    "\n",
    "from ultralytics import RTDETR\n",
    "import wget\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# モデルが未定義ならロードする\n",
    "try:\n",
    "    model  # 変数modelが定義されているか確認\n",
    "except NameError:\n",
    "    print(\"modelが未定義のため、ロードを実行します。\")\n",
    "    model = RTDETR(r\"C:\\Users\\ykita\\FacePhoto_instance\\models\\135best_rtdetr.pt\")\n",
    "\n",
    "# 画像URLの指定\n",
    "url = \"https://365dentist.jp/wp-content/uploads/2023/06/26579868_s.jpg\"\n",
    "\n",
    "# 画像のダウンロード\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# 推論実行\n",
    "results = model(img)\n",
    "\n",
    "# 結果の表示と保存\n",
    "for r in results:\n",
    "    # 画像をプロットして表示\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(r.plot(), cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RT-DETR トレーニングフォルダ構成**\n",
    "```\n",
    "準備する形\n",
    "project_root/\n",
    "│\n",
    "└── data/\n",
    "    |\n",
    "    │\n",
    "    ├── images/ --> データセットから移行\n",
    "    │   ├── img1.jpg\n",
    "    │   ├── img2.jpg\n",
    "    │   └── ...\n",
    "    │   \n",
    "    ├── labels/ --> CVATからそのまま移す      　　　\n",
    "    |       ├── img1.txt\n",
    "    |       ├── img2.txt\n",
    "    |       └── ...\n",
    "    |\n",
    "    | \n",
    "    ├── Train.txt　　　　　　# トレーニングファイルのリスト --> CVATからそのまま移す\n",
    "    │\n",
    "    └── dataset.yaml        # データセット設定ファイル  --> 新たに作成\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "最終形\n",
    "project_root/\n",
    "│\n",
    "└── data/\n",
    "    |\n",
    "    │\n",
    "    ├── train/\n",
    "    │   ├── images/       # トレーニング用の画像\n",
    "    │   │   ├── img1.jpg\n",
    "    │   │   ├── img2.jpg\n",
    "    │   │   └── ...\n",
    "    │   │\n",
    "    │   └── labels/      # トレーニング用のラベル（アノテーション）\n",
    "    │       ├── img1.txt\n",
    "    │       ├── img2.txt\n",
    "    │       └── ...\n",
    "    │\n",
    "    ├── val/\n",
    "    │   ├── images/      # 検証用の画像\n",
    "    │   │   ├── img1.jpg\n",
    "    │   │   └── ...\n",
    "    │   │\n",
    "    │   └── labels/     # 検証用のラベル\n",
    "    │       ├── img1.txt\n",
    "    │       └── ...\n",
    "    │\n",
    "    ├── test/           # (オプション) テスト用のデータセット\n",
    "    |   ├── images/\n",
    "    |   └── labels/\n",
    "    │\n",
    "    ├── Train.txt           # トレーニングファイルのリスト\n",
    "    │\n",
    "    └── dataset.yaml        # データセット設定ファイル:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **dataset.yaml**\n",
    "\n",
    "```\n",
    "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
    "train: ./data/images/train\n",
    "val: ./data/images/valid\n",
    "\n",
    "# number of classes\n",
    "nc: 2\n",
    "\n",
    "# class names:\n",
    "  0: Right_eye\n",
    "  1: Left_eye\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ラベルが存在しない画像ファイルの数: 0\n"
     ]
    }
   ],
   "source": [
    "# データの前処理\n",
    "# 目的: 画像ファイルとラベルファイルの対応関係を確認\n",
    "# 処理内容:\n",
    "# 1. ラベルディレクトリとイメージディレクトリのパスを設定\n",
    "# 2. 各ディレクトリからファイル名(拡張子なし)を取得\n",
    "# 3. ラベルが存在しない画像ファイルを特定\n",
    "# 4. 不一致の数を表示\n",
    "\n",
    "import os\n",
    "\n",
    "# ラベルとイメージのディレクトリパス\n",
    "labels_dir = r\"data\\labels\"\n",
    "images_dir = r\"data\\images\"\n",
    "\n",
    "# ラベルファイルの basename (拡張子なし) を取得\n",
    "label_files = {os.path.splitext(f)[0] for f in os.listdir(labels_dir) if f.endswith('.txt')}\n",
    "\n",
    "# 画像ファイルの basename (拡張子なし) を取得\n",
    "image_files = {os.path.splitext(f)[0] for f in os.listdir(images_dir) if f.endswith('.jpg')}\n",
    "\n",
    "# ラベルが存在しない画像ファイルを見つける\n",
    "images_without_labels = image_files - label_files\n",
    "\n",
    "# 結果を表示\n",
    "print(f\"ラベルが存在しない画像ファイルの数: {len(images_without_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不一致ファイルの削除が完了しました\n"
     ]
    }
   ],
   "source": [
    "# ラベルが存在しない画像ファイルを削除\n",
    "for img_name in images_without_labels:\n",
    "    img_path = os.path.join(images_dir, img_name + '.jpg')\n",
    "    try:\n",
    "        os.remove(img_path)\n",
    "        print(f\"削除しました: {img_path}\")\n",
    "    except OSError as e:\n",
    "        print(f\"削除に失敗しました {img_path}: {e}\")\n",
    "\n",
    "print(\"不一致ファイルの削除が完了しました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "見つかった画像ファイル数: 888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "trainデータの移動: 100%|██████████| 710/710 [00:00<00:00, 1022.90it/s]\n",
      "validデータの移動: 100%|██████████| 178/178 [00:00<00:00, 1002.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数: 710\n",
      "検証データ数: 178\n",
      "データの分割と移動が完了しました\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 指定されたディレクトリから画像ファイル(.jpg, .png, .tif)を取得\n",
    "# 2. 画像ファイルをランダムに並び替え\n",
    "# 3. train/validディレクトリを作成\n",
    "# 4. データを8:2の比率で分割\n",
    "# 5. 画像ファイルと対応するラベルファイル(.txt)を適切なディレクトリに移動\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# データディレクトリのパス設定\n",
    "data_img_dir = r\"data\\images\"\n",
    "data_label_dir = r\"data\\labels\"\n",
    "src_img_dir = r\"data\\images\"\n",
    "src_label_dir = r\"data\\labels\"\n",
    "\n",
    "# ソースディレクトリの画像ファイルを直接取得（サブディレクトリを除く）\n",
    "image_files = [f for f in os.listdir(src_img_dir) \n",
    "               if f.lower().endswith(('.jpg', '.jpeg', '.png', '.tif', '.tiff')) \n",
    "               and os.path.isfile(os.path.join(src_img_dir, f))]\n",
    "\n",
    "if not image_files:\n",
    "    print(\"エラー: 画像ファイルが見つかりません\")\n",
    "else:\n",
    "    print(f\"見つかった画像ファイル数: {len(image_files)}\")\n",
    "    \n",
    "    # train/validディレクトリの作成\n",
    "    for split in ['train', 'valid']:\n",
    "        img_split_dir = os.path.join(data_img_dir, split)\n",
    "        label_split_dir = os.path.join(data_label_dir, split)\n",
    "        \n",
    "        os.makedirs(img_split_dir, exist_ok=True)\n",
    "        os.makedirs(label_split_dir, exist_ok=True)\n",
    "\n",
    "    # データの分割\n",
    "    random.shuffle(image_files)\n",
    "    train_size = int(len(image_files) * 0.8)\n",
    "    train_files = image_files[:train_size]\n",
    "    valid_files = image_files[train_size:]\n",
    "\n",
    "    # ファイルの移動関数\n",
    "    def move_files(files, split):\n",
    "        for img_file in tqdm(files, desc=f\"{split}データの移動\"):\n",
    "            try:\n",
    "                # 画像ファイルの移動\n",
    "                src_img_path = os.path.join(src_img_dir, img_file)\n",
    "                dst_img_path = os.path.join(data_img_dir, split, img_file)\n",
    "                \n",
    "                if os.path.exists(src_img_path):\n",
    "                    shutil.move(src_img_path, dst_img_path)\n",
    "\n",
    "                # 対応するラベルファイルの移動\n",
    "                label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "                src_label_path = os.path.join(src_label_dir, label_file)\n",
    "                dst_label_path = os.path.join(data_label_dir, split, label_file)\n",
    "                \n",
    "                if os.path.exists(src_label_path):\n",
    "                    shutil.move(src_label_path, dst_label_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"エラーが発生しました ({img_file}): {str(e)}\")\n",
    "\n",
    "    # trainとvalidそれぞれにファイルを移動\n",
    "    move_files(train_files, 'train')\n",
    "    move_files(valid_files, 'valid')\n",
    "\n",
    "    print(f\"訓練データ数: {len(train_files)}\")\n",
    "    print(f\"検証データ数: {len(valid_files)}\")\n",
    "    print(\"データの分割と移動が完了しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **YAMLファイルを作成 (for training)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "既存の data/data.yaml を上書きします。\n",
      "処理が完了しました。\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "data = {\n",
    "    'train': 'C:\\Users\\ykita\\ROP_AI_project\\data\\images\\train',\n",
    "    'val': 'C:\\Users\\ykita\\ROP_AI_project\\data\\images\\valid',\n",
    "    'nc': 1,\n",
    "    'names': {\n",
    "        0: 'Lens',\n",
    "    }\n",
    "}\n",
    "\n",
    "yaml_path = 'data/data.yaml'\n",
    "\n",
    "# dataディレクトリが存在しない場合は作成\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# ファイルの存在確認\n",
    "if os.path.exists(yaml_path):\n",
    "    print(f\"既存の {yaml_path} を上書きします。\")\n",
    "else:\n",
    "    print(f\"新規に {yaml_path} を作成します。\")\n",
    "\n",
    "# YAMLファイルの書き出し（既存ファイルは上書き）\n",
    "with open(yaml_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.safe_dump(data, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"処理が完了しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train RT-DETR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.59  Python-3.8.6 torch-2.4.1+cu121 CUDA:0 (Quadro RTX 5000, 16384MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=models\\rtdetr-l.pt, data=data\\data.yaml, epochs=600, time=None, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "WARNING  no model scale passed. Assuming scale='l'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n",
      "  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n",
      "  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n",
      "  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n",
      "  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n",
      "  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n",
      "  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n",
      "  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n",
      "  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n",
      " 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n",
      " 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n",
      " 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n",
      " 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n",
      " 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n",
      " 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n",
      " 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \n",
      "rt-detr-l summary: 681 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n",
      "\n",
      "Transferred 926/941 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 29.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\ykita\\ROP_AI_project\\data\\labels\\train... 710 images, 0 backgrounds, 0 corrupt: 100%|██████████| 710/710 [00:01<00:00, 532.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\ykita\\ROP_AI_project\\data\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ykita\\ROP_AI_project\\data\\labels\\valid... 178 images, 0 backgrounds, 0 corrupt: 100%|██████████| 178/178 [00:00<00:00, 406.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\ykita\\ROP_AI_project\\data\\labels\\valid.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train6\u001b[0m\n",
      "Starting training for 600 epochs...\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89 [00:00<?, ?it/s]c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:87.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      1/600      7.01G     0.1601       3.61     0.1634         10        640: 100%|██████████| 89/89 [01:01<00:00,  1.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        178        178      0.965      0.989      0.989      0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89 [00:00<?, ?it/s]c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:87.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      2/600      7.18G    0.08338     0.2424    0.07102         10        640: 100%|██████████| 89/89 [00:55<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        178        178      0.988      0.989      0.989      0.955\n",
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89 [00:00<?, ?it/s]c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:87.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      3/600      7.16G       0.11     0.3171    0.09498         13        640: 100%|██████████| 89/89 [00:56<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        178        178        nan      0.826      0.602       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89 [00:00<?, ?it/s]c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:87.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      4/600      7.27G     0.1331     0.6548     0.1158         17        640: 100%|██████████| 89/89 [00:55<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        178        178        nan      0.129     0.0915     0.0852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89 [00:00<?, ?it/s]c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:87.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      5/600      7.26G     0.1582     0.4594      0.142          9        640: 100%|██████████| 89/89 [00:56<00:00,  1.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        178        178        nan     0.0169      0.015      0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89 [00:00<?, ?it/s]c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:87.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      6/600      7.27G     0.1249     0.4252     0.1075         14        640: 100%|██████████| 89/89 [00:55<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        178        178        nan       0.68      0.675      0.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/89 [00:00<?, ?it/s]c:\\Users\\ykita\\ROP_AI_project\\ropenv\\lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\Context.cpp:87.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "      7/600      7.27G     0.1244     0.4224     0.1051         11        640: 100%|██████████| 89/89 [00:53<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03<00:00,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        178        178        nan      0.674      0.668      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import RTDETR\n",
    "\n",
    "# RTDETRモデルのダウンロードと初期化\n",
    "try:\n",
    "    model = RTDETR(r'models\\rtdetr-l.pt')\n",
    "except:\n",
    "    wget.download('https://github.com/ultralytics/assets/releases/download/v0.0.0/rtdetr-l.pt')\n",
    "    model = RTDETR(r'models\\rtdetr-l.pt')\n",
    "\n",
    "# Fine-tune\n",
    "results = model.train(data=r'data\\data.yaml', epochs=600, batch=8, imgsz=640, device=0, patience=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instanceenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
